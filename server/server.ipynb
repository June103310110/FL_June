{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初始化超參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZMQInteractiveShell\n"
     ]
    }
   ],
   "source": [
    "from IPython import get_ipython\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "print(get_ipython().__class__.__name__)\n",
    "if get_ipython().__class__.__name__ == 'ZMQInteractiveShell':\n",
    "    pass\n",
    "else:\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--new_model\", help=\"if initialize a new model or not, [default]:False\",\n",
    "                       default = False, required=False)\n",
    "    args = parser.parse_args()\n",
    "    print(vars(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "contro_key = {}\n",
    "if 'args' in locals():\n",
    "    for i in vars(args).keys():\n",
    "        contro_key[i] = vars(args)[i]\n",
    "else:\n",
    "    contro_key['new_model'] = False\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 確認Git權限，並取得操作程序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gitURL': 'https://gitlab.com/aia-federated-0121/june-federated-server.git', 'account': 'aiafederated0121:federated0121'}\n"
     ]
    }
   ],
   "source": [
    "gitURL = 'https://gitlab.aiacademy.tw/junew/federated_aia_test.git'\n",
    "account = 'at102091:12345678'\n",
    "\n",
    "with open('../../FL_June/account.cfg', 'r') as f:\n",
    "    r = f.read()\n",
    "    \n",
    "    dic = {}\n",
    "    for i in r.splitlines():\n",
    "        i = [item.strip() for item in i.split('=')]\n",
    "#         print(i.split('='))\n",
    "        dic[i[0]] = i[1]\n",
    "    print(dic)\n",
    "gitURL = dic['gitURL']\n",
    "account = dic['account']\n",
    "\n",
    "# print(gitURL, account)|\n",
    "# repo_name = 'june-federated-server'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'june-federated-server'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gitlab.com/aia-federated-0121/june-federated-server.git cloning to  /home/jovyan/git/FL_June/server\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: Remote branch master not found in upstream origin\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if os.getcwd().split('/')[-2:] == ['FL_June', 'server']:\n",
    "    os.popen('git clone -b master https://{account}@{gitURL}'.format(account=account,\n",
    "                                                           gitURL=gitURL.split('//')[-1])).read()\n",
    "\n",
    "    print(gitURL.split('//')[-1], 'cloning to ',os.getcwd())\n",
    "else:\n",
    "    print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 開始server運作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-11 11:57:08.657627: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'federated_aia_test'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8943/636780538.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfederated_aia_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompressed_cpickle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecompress_cpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'federated_aia_test'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (Input, Dense, Dropout, Activation,\n",
    "                                     BatchNormalization, Flatten,\n",
    "                                     Conv2D, MaxPooling2D)\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from federated_aia_test.utils import compressed_cpickle, decompress_cpickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 移動到federated_aia_test floder\n",
    "如果不存在，請先執行最上面的git clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getcwd())\n",
    "if os.getcwd().split('/')[-2:] == ['server', 'federated_aia_test']:\n",
    "    pass\n",
    "else:\n",
    "    os.chdir('../../FL_June/server/federated_aia_test')\n",
    "    os.getcwd()\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立新的初始化global model \n",
    "> 只有當模型不存在、或者你更新了架構、打算重新訓練的時候"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(contro_key['new_model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplecnn():\n",
    "    # 選擇 Keras 的 API 寫法\n",
    "    inputs = Input(shape=(28,28,1))\n",
    "#     inputs = inputs\n",
    "    # 第一層\n",
    "    # 建立卷積層，設定32個3*3的filters\n",
    "    # 設定ReLU為激活函數。\n",
    "    x = Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "\n",
    "    # 第二層 - 卷積層 + 池化層\n",
    "    x = Conv2D(32, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # 第三層 - 卷積層\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "\n",
    "    # 第四層 - 卷積層 + 池化層\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # 建立分類模型 (MLP) : 平坦層 + 輸出層 (10)\n",
    "    x = Flatten()(x)\n",
    "    outputs = Dense(10, activation='softmax')(x)\n",
    "\n",
    "    cnn_model = Model(inputs=inputs, outputs=outputs)\n",
    "    return cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if contro_key['new_model'] == True:\n",
    "    import os\n",
    "    import shutil\n",
    "    from datetime import date\n",
    "    \n",
    "    # 保留舊模型到server本機 (saved_model被登錄在.gitignore)\n",
    "    os.makedirs('../saved_model', exist_ok=True)\n",
    "    if os.listdir().__contains__('global_model.pbz2'):\n",
    "        today = date.today()\n",
    "        lis = os.listdir('../saved_model')\n",
    "        lis = [i for i in lis if i.__contains__('global_model')]\n",
    "        \n",
    "        new_model_name = 'global_model_{ver}_{today}.pbz2'.format(today=today, ver=len(lis))\n",
    "        shutil.move('./global_model.pbz2', '../saved_model/'+new_model_name)\n",
    "        print('Move global model to FL_June/server/saved_model')\n",
    "    else:\n",
    "        pass\n",
    "    model = simplecnn()\n",
    "\n",
    "    # weight、架構 (json) to pickle\n",
    "\n",
    "    model_attri = {'weights':model.get_weights(), 'json':model.to_json()}\n",
    "    \n",
    "    print('create new model')\n",
    "    compressed_cpickle('./global_model', model_attri)\n",
    "\n",
    "    print('update gitrepo global_model.pbz2')\n",
    "    run_cmd = lambda cmd_lis:[os.popen(i).read() for i in cmd_lis.split('\\n')]\n",
    "    cmd_lis = '''git add .\n",
    "    git commit -m'global model complete aggregate and update to g'\n",
    "    git push https://{account}@{gitURL}\n",
    "    '''.format(account=account, gitURL=gitURL.split('//')[-1])\n",
    "    \n",
    "    \n",
    "    run_cmd(cmd_lis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 選擇本輪參與的參與者，並更新round和training.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contro_key['C'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "C = contro_key['C']\n",
    "\n",
    "r = os.popen('git pull').read()\n",
    "print(r)\n",
    "\n",
    "os.popen('git remote update origin --prune')\n",
    "lis = os.popen('git branch -r').read().split('\\n')[:-1]\n",
    "\n",
    "\n",
    "all_client_branch = [i.strip().split('/')[-1] for i in lis if not i.__contains__('master')]\n",
    "\n",
    "print(all_client_branch)\n",
    "\n",
    "participate_branch = random.sample(all_client_branch, int(C*len(all_client_branch)))\n",
    "print(participate_branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./training.cfg', mode='r', encoding='UTF-8') as f:\n",
    "    r = f.readlines()\n",
    "    item_dict = {}\n",
    "    for item in r:\n",
    "        key, value = item.split('=')\n",
    "        item_dict[key] = value.split('\\n')[0]\n",
    "\n",
    "item_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounds = int(item_dict['round'])+1\n",
    "print(rounds)\n",
    "print(participate_branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./training.cfg', mode='w+', encoding='UTF-8') as f:\n",
    "    f.writelines('round={rounds}\\n'.format(rounds=rounds))\n",
    "    f.writelines('trainKey={participate_branch}\\n'.format(participate_branch='/'.join(all_client_branch)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下載各個branch中的模型壓縮檔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n",
      "\n",
      "['  origin/HEAD -> origin/main', '  origin/main', '  origin/teaching_sample']\n"
     ]
    }
   ],
   "source": [
    "r = os.popen('git pull').read()\n",
    "print(r)\n",
    "\n",
    "os.popen('git remote update origin --prune')\n",
    "lis = os.popen('git branch -r').read().split('\\n')[:-1]\n",
    "\n",
    "\n",
    "all_client_branch = [i for i in  lis if not i.__contains__('master')]\n",
    "\n",
    "print(all_client_branch)\n",
    "\n",
    "# 判斷各個分支是否有更新\n",
    "if len(all_client_branch) <= 0:\n",
    "    raise ValueError('June: No clients appear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin/HEAD -> origin/main main.pbz2\n",
      "\n",
      "origin/main main.pbz2\n",
      "\n",
      "origin/teaching_sample teaching_sample.pbz2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: cannot create origin/main: Directory nonexistent\n",
      "error: pathspec 'main.pbz2' did not match any file(s) known to git.\n",
      "error: pathspec 'teaching_sample.pbz2' did not match any file(s) known to git.\n"
     ]
    }
   ],
   "source": [
    "run_cmd = lambda cmd_lis:[os.popen(i).read() for i in cmd_lis.split('\\n')]\n",
    "\n",
    "for i in all_client_branch:\n",
    "    origin_branch_name = i.lstrip()\n",
    "    filename = origin_branch_name.split('/')[-1]+'.pbz2'\n",
    "    \n",
    "    print(origin_branch_name, filename)\n",
    "    \n",
    "    \n",
    "    cmd_lis = '''git checkout remotes/{branch_name} {model_attri_pbz2}\n",
    "    '''.format(branch_name = origin_branch_name, model_attri_pbz2=filename)\n",
    "    result = os.popen(cmd_lis).read()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 聚合並更新global model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "list.remove(x): x not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8943/1917926692.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mglobal_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_from_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_attri\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'json'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./global_model.pbz2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mlis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'global_model.pbz2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: list.remove(x): x not in list"
     ]
    }
   ],
   "source": [
    "lis = [i for i in os.listdir() if i.__contains__('pbz2')]\n",
    "if 'global_model.pbz2' in lis:\n",
    "    model_attri = decompress_cpickle('./global_model.pbz2')\n",
    "    global_model = tf.keras.models.model_from_json(model_attri['json'])\n",
    "    os.remove('./global_model.pbz2')\n",
    "lis.remove('global_model.pbz2')\n",
    "print(lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 10)\n"
     ]
    }
   ],
   "source": [
    "weights = []\n",
    "for i in lis:\n",
    "    model_attri = decompress_cpickle(i)\n",
    "    weights.append(model_attri['weights'])\n",
    "print(np.shape(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_weights = list()\n",
    "if len(weights) == 0:\n",
    "    print('no new client to aggregate')\n",
    "    pass\n",
    "elif len(weights) == 1:\n",
    "    print('only single participant')\n",
    "    new_weights = weights[0]\n",
    "else:\n",
    "    for i in zip(*weights):\n",
    "        new_weights.append(tf.reduce_sum(i, axis=0))\n",
    "        \n",
    "global_model.set_weights(new_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_attri = {'weights':global_model.get_weights(), 'json':global_model.to_json()}\n",
    "\n",
    "compressed_cpickle('./global_model', model_attri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "[master 96a6048] global model complete aggregate and update to Gmodel\n",
      " 2 files changed, 2 insertions(+), 2 deletions(-)\n",
      " rewrite global_model.pbz2 (95%)\n",
      "\n",
      "\n",
      "\n",
      "* master\n",
      "  remotes/origin/6uKEQVbD8SvvHkm5DAdhmQ\n",
      "  remotes/origin/FNLT9OFPkRCfcrzle7BrJg\n",
      "  remotes/origin/HEAD -> origin/master\n",
      "  remotes/origin/KJugrbO2x4I0JwkYIaLNFQ\n",
      "  remotes/origin/S_I7VIt4yMEZLQXNw5RXzA\n",
      "  remotes/origin/T_gHdTLAsBgPd-mt3Vx-3w\n",
      "  remotes/origin/WRDXd_4cC3Ce9w-8bv675g\n",
      "  remotes/origin/master\n",
      "  remotes/origin/pv-Tlkw3Dk4EWNx7GnpIrA\n",
      "  remotes/origin/rblifDbWO_SZDrpqlU9YdQ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "run_cmd = lambda cmd_lis:[os.popen(i).read() for i in cmd_lis.split('\\n')]\n",
    "\n",
    "cmd_lis = '''mv ./global_model.pbz2 ../\n",
    "rm *.pbz2\n",
    "mv ../global_model.pbz2 ./\n",
    "git add .\n",
    "git commit -m'global model complete aggregate and update to Gmodel'\n",
    "git push https://{account}@{gitURL}\n",
    "'''.format(account=account, gitURL=gitURL.split('//')[-1])\n",
    "\n",
    "\n",
    "result = run_cmd(cmd_lis)\n",
    "for i in result:\n",
    "    print(i)\n",
    "branch = os.popen('git branch -a').read()\n",
    "print(branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZMQInteractiveShell\n"
     ]
    }
   ],
   "source": [
    "from IPython import get_ipython\n",
    "import os\n",
    "\n",
    "print(get_ipython().__class__.__name__)\n",
    "if get_ipython().__class__.__name__ == 'ZMQInteractiveShell':\n",
    "    os.popen('ipython nbconvert --to script ../server.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
