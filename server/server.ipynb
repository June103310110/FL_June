{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@param {type:\"boolean\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gitURL': 'https://gitlab.com/aia-federated-0121/june-federated-server.git', 'account': 'aiafederated0121:federated0121'}\n"
     ]
    }
   ],
   "source": [
    "# gitURL = 'https://gitlab.aiacademy.tw/junew/federated_aia_test.git'\n",
    "# account = 'at102091:12345678'\n",
    "\n",
    "with open('./account.cfg', 'r') as f:\n",
    "    r = f.read()\n",
    "    \n",
    "    dic = {}\n",
    "    for i in r.splitlines():\n",
    "        i = [item.strip() for item in i.split('=')]\n",
    "#         print(i.split('='))\n",
    "        dic[i[0]] = i[1]\n",
    "    print(dic)\n",
    "gitURL = dic['gitURL']\n",
    "account = dic['account']\n",
    "repo_name = 'june-federated-server'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'june-federated-server'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clone to  /home/jovyan/git/FL_June/server\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if os.getcwd().split('/')[-2:] == ['FL_June', 'server']:\n",
    "    os.popen('git clone https://{account}@{gitURL}'.format(account=account,\n",
    "                                                           gitURL=gitURL.split('//')[-1])).read()\n",
    "    print('clone to ',os.getcwd())\n",
    "else:\n",
    "    print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-11 18:06:49.958189: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (Input, Dense, Dropout, Activation,\n",
    "                                     BatchNormalization, Flatten,\n",
    "                                     Conv2D, MaxPooling2D)\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "import sys\n",
    "sys.path.append(f'./{repo_name}/')\n",
    "from utils import compressed_cpickle, decompress_cpickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### control_key (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "contro_key = {}\n",
    "contro_key['new_model'] = False # default to False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 移動到federated_aia_test floder\n",
    "如果不存在，請先執行最上面的git clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/git/FL_June/server\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "if os.getcwd().split('/')[-2:] == ['server', 'june-federated-servert']:\n",
    "    pass\n",
    "else:\n",
    "    os.chdir('../../FL_June/server/june-federated-server')\n",
    "    os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立新的初始化global model \n",
    "> 只有當模型不存在、或者你更新了架構、打算重新訓練的時候"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplecnn():\n",
    "    # 選擇 Keras 的 API 寫法\n",
    "    inputs = Input(shape=(28,28,1))\n",
    "#     inputs = inputs\n",
    "    # 第一層\n",
    "    # 建立卷積層，設定32個3*3的filters\n",
    "    # 設定ReLU為激活函數。\n",
    "    x = Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "\n",
    "    # 第二層 - 卷積層 + 池化層\n",
    "    x = Conv2D(32, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # 第三層 - 卷積層\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "\n",
    "    # 第四層 - 卷積層 + 池化層\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # 建立分類模型 (MLP) : 平坦層 + 輸出層 (10)\n",
    "    x = Flatten()(x)\n",
    "    outputs = Dense(10, activation='softmax')(x)\n",
    "\n",
    "    cnn_model = Model(inputs=inputs, outputs=outputs)\n",
    "    return cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-11\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "import pathlib\n",
    "\n",
    "today = date.today()\n",
    "print(today)\n",
    "\n",
    "path = '../saved_model'\n",
    "pathlib.Path(f'{path}').mkdir(parents=True, exist_ok=True)     \n",
    "lis = os.listdir(path)\n",
    "lis = [i for i in lis if i.__contains__('global_model')]\n",
    "print(lis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if contro_key['new_model'] == True:\n",
    "    import os\n",
    "    import shutil\n",
    "    from datetime import date\n",
    "    \n",
    "    # 保留舊模型到server本機 (saved_model被登錄在.gitignore)\n",
    "    os.makedirs('../saved_model', exist_ok=True)\n",
    "    if os.listdir().__contains__('global_model.pbz2'):\n",
    "        today = date.today()\n",
    "        lis = os.listdir('../saved_model')\n",
    "        lis = [i for i in lis if i.__contains__('global_model')]\n",
    "        \n",
    "        new_model_name = 'global_model_{ver}_{today}.pbz2'.format(today=today, ver=len(lis))\n",
    "        shutil.move('./global_model.pbz2', '../saved_model/'+new_model_name)\n",
    "        print('Move global model to FL_June/server/saved_model')\n",
    "    else:\n",
    "        pass\n",
    "    model = simplecnn()\n",
    "\n",
    "    # weight、架構 (json) to pickle\n",
    "\n",
    "    model_attri = {'weights':model.get_weights(), 'json':model.to_json()}\n",
    "    \n",
    "    print('create new model')\n",
    "    compressed_cpickle('./global_model', model_attri)\n",
    "\n",
    "    print('update gitrepo global_model.pbz2')\n",
    "    run_cmd = lambda cmd_lis:[os.popen(i).read() for i in cmd_lis.split('\\n')]\n",
    "    cmd_lis = '''git add .\n",
    "    git commit -m'global model complete aggregate and update to g'\n",
    "    git push https://{account}@{gitURL}\n",
    "    '''.format(account=account, gitURL=gitURL.split('//')[-1])\n",
    "    \n",
    "    \n",
    "    run_cmd(cmd_lis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下載各個branch中的模型壓縮檔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n",
      "\n",
      "['  origin/BxipCjg_WfS0amO30vC6mQ', '  origin/MKkWS7qXBbnugNAEXN8PEg', '  origin/Ntyfcj14jPRiW4iWiNa2PA', '  origin/VA6GWv7MfvF1OnnLj0Ra3w', '  origin/ZmUvKOfUgOhilDwuPALTWA']\n"
     ]
    }
   ],
   "source": [
    "r = os.popen('git pull').read()\n",
    "print(r)\n",
    "\n",
    "os.popen('git remote update origin --prune')\n",
    "lis = os.popen('git branch -r').read().split('\\n')[:-1]\n",
    "\n",
    "\n",
    "all_client_branch = [i for i in  lis if not i.__contains__('main')]\n",
    "\n",
    "print(all_client_branch)\n",
    "\n",
    "# 判斷各個分支是否有更新\n",
    "if len(all_client_branch) <= 0:\n",
    "    raise ValueError('June: No clients appear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* \u001b[32mmain\u001b[m\n",
      "  \u001b[31mremotes/origin/BxipCjg_WfS0amO30vC6mQ\u001b[m\n",
      "  \u001b[31mremotes/origin/HEAD\u001b[m -> origin/main\n",
      "  \u001b[31mremotes/origin/MKkWS7qXBbnugNAEXN8PEg\u001b[m\n",
      "  \u001b[31mremotes/origin/Ntyfcj14jPRiW4iWiNa2PA\u001b[m\n",
      "  \u001b[31mremotes/origin/VA6GWv7MfvF1OnnLj0Ra3w\u001b[m\n",
      "  \u001b[31mremotes/origin/ZmUvKOfUgOhilDwuPALTWA\u001b[m\n",
      "  \u001b[31mremotes/origin/main\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!git branch -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lis = [i.split('/')[-1] for i in all_client_branch]\n",
    "for i in all_lis:\n",
    "    if not i in [_.split('.')[0] for _ in lis]:\n",
    "        print(i)\n",
    "        remote_name = 'origin'\n",
    "        branch_name = i\n",
    "        os.popen(f'git branch -d {branch_name}')\n",
    "        os.popen(f'git push {remote_name} --delete {branch_name}').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin/BxipCjg_WfS0amO30vC6mQ BxipCjg_WfS0amO30vC6mQ.pbz2\n",
      "\n",
      "origin/MKkWS7qXBbnugNAEXN8PEg MKkWS7qXBbnugNAEXN8PEg.pbz2\n",
      "\n",
      "origin/Ntyfcj14jPRiW4iWiNa2PA Ntyfcj14jPRiW4iWiNa2PA.pbz2\n",
      "\n",
      "origin/VA6GWv7MfvF1OnnLj0Ra3w VA6GWv7MfvF1OnnLj0Ra3w.pbz2\n",
      "\n",
      "origin/ZmUvKOfUgOhilDwuPALTWA ZmUvKOfUgOhilDwuPALTWA.pbz2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_cmd = lambda cmd_lis:[os.popen(i).read() for i in cmd_lis.split('\\n')]\n",
    "\n",
    "for i in all_client_branch:\n",
    "    origin_branch_name = i.lstrip()\n",
    "    filename = origin_branch_name.split('/')[-1]+'.pbz2'\n",
    "    \n",
    "    print(origin_branch_name, filename)\n",
    "    \n",
    "    \n",
    "    cmd_lis = '''git checkout remotes/{branch_name} {model_attri_pbz2}\n",
    "    '''.format(branch_name = origin_branch_name, model_attri_pbz2=filename)\n",
    "    result = os.popen(cmd_lis).read()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 聚合並更新global model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-11 18:06:52.784183: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-01-11 18:06:52.785036: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-01-11 18:06:52.917087: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:06:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-01-11 18:06:52.919864: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:07:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-01-11 18:06:52.922611: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties: \n",
      "pciBusID: 0000:0f:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-01-11 18:06:52.922633: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-01-11 18:06:52.925730: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2022-01-11 18:06:52.925775: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-01-11 18:06:52.927237: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-01-11 18:06:52.927521: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-01-11 18:06:52.930869: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-01-11 18:06:52.931641: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-01-11 18:06:52.931803: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-01-11 18:06:52.947849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1, 2\n",
      "2022-01-11 18:06:52.948368: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-11 18:06:52.948941: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-01-11 18:06:53.477655: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:06:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-01-11 18:06:53.480034: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:07:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-01-11 18:06:53.482397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties: \n",
      "pciBusID: 0000:0f:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-01-11 18:06:53.482432: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-01-11 18:06:53.482474: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2022-01-11 18:06:53.482490: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-01-11 18:06:53.482505: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-01-11 18:06:53.482523: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-01-11 18:06:53.482539: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-01-11 18:06:53.482554: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-01-11 18:06:53.482570: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-01-11 18:06:53.497893: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1, 2\n",
      "2022-01-11 18:06:53.497935: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-01-11 18:06:54.935427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-01-11 18:06:54.935459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 2 \n",
      "2022-01-11 18:06:54.935466: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N Y Y \n",
      "2022-01-11 18:06:54.935469: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   Y N Y \n",
      "2022-01-11 18:06:54.935473: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 2:   Y Y N \n",
      "2022-01-11 18:06:54.947684: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10271 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:06:00.0, compute capability: 6.1)\n",
      "2022-01-11 18:06:54.952669: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10271 MB memory) -> physical GPU (device: 1, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:07:00.0, compute capability: 6.1)\n",
      "2022-01-11 18:06:54.957570: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 10271 MB memory) -> physical GPU (device: 2, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:0f:00.0, compute capability: 6.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MKkWS7qXBbnugNAEXN8PEg.pbz2', 'BxipCjg_WfS0amO30vC6mQ.pbz2', 'ZmUvKOfUgOhilDwuPALTWA.pbz2', 'Ntyfcj14jPRiW4iWiNa2PA.pbz2', 'VA6GWv7MfvF1OnnLj0Ra3w.pbz2']\n"
     ]
    }
   ],
   "source": [
    "model_attri = decompress_cpickle('./global_model.pbz2')\n",
    "global_model = tf.keras.models.model_from_json(model_attri['json'])\n",
    "\n",
    "lis = [i for i in os.listdir() if i.__contains__('pbz2')]\n",
    "lis.remove('global_model.pbz2')\n",
    "print(lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "lis = [i for i in os.listdir() if i.__contains__('pbz2')]\n",
    "lis.remove('global_model.pbz2')\n",
    "\n",
    "weights = []\n",
    "for i in lis:\n",
    "    model_attri = decompress_cpickle(i)\n",
    "    weights.append(model_attri['weights'])\n",
    "print(np.shape(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_weights = list()\n",
    "if len(weights) == 0:\n",
    "    print('no new client to aggregate')\n",
    "    pass\n",
    "elif len(weights) == 1:\n",
    "    print('only single participant')\n",
    "    new_weights = weights[0]\n",
    "else:\n",
    "    for i in zip(*weights):\n",
    "        new_weights.append(tf.reduce_sum(i, axis=0))\n",
    "        \n",
    "global_model.set_weights(new_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_attri = {'weights':global_model.get_weights(), 'json':global_model.to_json()}\n",
    "\n",
    "compressed_cpickle('./global_model', model_attri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* main\n",
      "  remotes/origin/4dGzDd3zcrxHtI0Zi_9AFw\n",
      "  remotes/origin/8o0tEPEiAWeNwougHt6ZvA\n",
      "  remotes/origin/F4k-2fDTQJhtwGV-e8JujA\n",
      "  remotes/origin/HEAD -> origin/main\n",
      "  remotes/origin/MKkWS7qXBbnugNAEXN8PEg\n",
      "  remotes/origin/O6xI1TK_l7N5GWFtS5hmAA\n",
      "  remotes/origin/PYROTx-ffNpx0TuGz17tiA\n",
      "  remotes/origin/VA6GWv7MfvF1OnnLj0Ra3w\n",
      "  remotes/origin/YHkGOpzDYvFjJTkcCK4Zsw\n",
      "  remotes/origin/ZmUvKOfUgOhilDwuPALTWA\n",
      "  remotes/origin/fTqyc8MdnqzjpjB8V4oeOA\n",
      "  remotes/origin/kKQsmrKyn10y020ppbXgOw\n",
      "  remotes/origin/main\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://gitlab.com/aia-federated-0121/june-federated-server.git\n",
      "   f7c5429..5dc6300  main -> main\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "run_cmd = lambda cmd_lis:[os.popen(i).read() for i in cmd_lis.split('\\n')]\n",
    "\n",
    "cmd_lis = '''mv ./global_model.pbz2 ../\n",
    "rm *.pbz2\n",
    "mv ../global_model.pbz2 ./\n",
    "git add .\n",
    "git commit -m'global model complete aggregate and update to Gmodel'\n",
    "git push https://{account}@{gitURL}\n",
    "'''.format(account=account, gitURL=gitURL.split('//')[-1])\n",
    "\n",
    "\n",
    "run_cmd(cmd_lis)\n",
    "branch = os.popen('git branch -a').read()\n",
    "print(branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
