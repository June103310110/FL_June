{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@param {type:\"boolean\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gitURL': 'https://gitlab.com/aia-federated-0121/june-federated-server.git', 'account': 'aiafederated0121:federated0121'}\n"
     ]
    }
   ],
   "source": [
    "# gitURL = 'https://gitlab.aiacademy.tw/junew/federated_aia_test.git'\n",
    "# account = 'at102091:12345678'\n",
    "\n",
    "with open('./account.cfg', 'r') as f:\n",
    "    r = f.read()\n",
    "    \n",
    "    dic = {}\n",
    "    for i in r.splitlines():\n",
    "        i = [item.strip() for item in i.split('=')]\n",
    "#         print(i.split('='))\n",
    "        dic[i[0]] = i[1]\n",
    "    print(dic)\n",
    "gitURL = dic['gitURL']\n",
    "account = dic['account']\n",
    "repo_name = 'june-federated-server'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clone to  /home/jovyan/git/FL_June/server\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'june-federated-server' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if os.getcwd().split('/')[-2:] == ['FL_June', 'server']:\n",
    "    os.popen('git clone https://{account}@{gitURL}'.format(account=account,\n",
    "                                                           gitURL=gitURL.split('//')[-1])).read()\n",
    "    print('clone to ',os.getcwd())\n",
    "else:\n",
    "    print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-18 11:18:17.676301: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (Input, Dense, Dropout, Activation,\n",
    "                                     BatchNormalization, Flatten,\n",
    "                                     Conv2D, MaxPooling2D)\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "import sys\n",
    "sys.path.append(f'./{repo_name}/')\n",
    "from utils import compressed_cpickle, decompress_cpickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### control_key (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "contro_key = {}\n",
    "contro_key['new_model'] = False # default to False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 移動到federated_aia_test floder\n",
    "如果不存在，請先執行最上面的git clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/git/FL_June/server\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "if os.getcwd().split('/')[-2:] == ['server', 'june-federated-servert']:\n",
    "    pass\n",
    "else:\n",
    "    os.chdir('../../FL_June/server/june-federated-server')\n",
    "    os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立新的初始化global model \n",
    "> 只有當模型不存在、或者你更新了架構、打算重新訓練的時候"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplecnn():\n",
    "    # 選擇 Keras 的 API 寫法\n",
    "    inputs = Input(shape=(28,28,1))\n",
    "#     inputs = inputs\n",
    "    # 第一層\n",
    "    # 建立卷積層，設定32個3*3的filters\n",
    "    # 設定ReLU為激活函數。\n",
    "    x = Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "\n",
    "    # 第二層 - 卷積層 + 池化層\n",
    "    x = Conv2D(32, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # 第三層 - 卷積層\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "\n",
    "    # 第四層 - 卷積層 + 池化層\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # 建立分類模型 (MLP) : 平坦層 + 輸出層 (10)\n",
    "    x = Flatten()(x)\n",
    "    outputs = Dense(10, activation='softmax')(x)\n",
    "\n",
    "    cnn_model = Model(inputs=inputs, outputs=outputs)\n",
    "    return cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-18\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "import pathlib\n",
    "\n",
    "today = date.today()\n",
    "print(today)\n",
    "\n",
    "path = '../saved_model'\n",
    "pathlib.Path(f'{path}').mkdir(parents=True, exist_ok=True)     \n",
    "lis = os.listdir(path)\n",
    "lis = [i for i in lis if i.__contains__('global_model')]\n",
    "print(lis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if contro_key['new_model'] == True:\n",
    "    import os\n",
    "    import shutil\n",
    "    from datetime import date\n",
    "    \n",
    "    # 保留舊模型到server本機 (saved_model被登錄在.gitignore)\n",
    "    os.makedirs('../saved_model', exist_ok=True)\n",
    "    if os.listdir().__contains__('global_model.pbz2'):\n",
    "        today = date.today()\n",
    "        lis = os.listdir('../saved_model')\n",
    "        lis = [i for i in lis if i.__contains__('global_model')]\n",
    "        \n",
    "        new_model_name = 'global_model_{ver}_{today}.pbz2'.format(today=today, ver=len(lis))\n",
    "        shutil.move('./global_model.pbz2', '../saved_model/'+new_model_name)\n",
    "        print('Move global model to FL_June/server/saved_model')\n",
    "    else:\n",
    "        pass\n",
    "    model = simplecnn()\n",
    "\n",
    "    # weight、架構 (json) to pickle\n",
    "\n",
    "    model_attri = {'weights':model.get_weights(), 'json':model.to_json()}\n",
    "    \n",
    "    print('create new model')\n",
    "    compressed_cpickle('./global_model', model_attri)\n",
    "\n",
    "    print('update gitrepo global_model.pbz2')\n",
    "    run_cmd = lambda cmd_lis:[os.popen(i).read() for i in cmd_lis.split('\\n')]\n",
    "    cmd_lis = '''git add .\n",
    "    git commit -m'global model complete aggregate and update to g'\n",
    "    git push https://{account}@{gitURL}\n",
    "    '''.format(account=account, gitURL=gitURL.split('//')[-1])\n",
    "    \n",
    "    \n",
    "    run_cmd(cmd_lis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下載各個branch中的模型壓縮檔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n",
      "\n",
      "['  origin/BxipCjg_WfS0amO30vC6mQ', '  origin/MKkWS7qXBbnugNAEXN8PEg', '  origin/Ntyfcj14jPRiW4iWiNa2PA', '  origin/Rj1cKm2wIS3f3NmKrQgX1g', '  origin/VA6GWv7MfvF1OnnLj0Ra3w', '  origin/ZmUvKOfUgOhilDwuPALTWA']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From https://gitlab.com/aia-federated-0121/june-federated-server\n",
      " * [new branch]      Rj1cKm2wIS3f3NmKrQgX1g -> origin/Rj1cKm2wIS3f3NmKrQgX1g\n"
     ]
    }
   ],
   "source": [
    "r = os.popen('git pull').read()\n",
    "print(r)\n",
    "\n",
    "os.popen('git remote update origin --prune')\n",
    "lis = os.popen('git branch -r').read().split('\\n')[:-1]\n",
    "\n",
    "\n",
    "all_client_branch = [i for i in  lis if not i.__contains__('main')]\n",
    "\n",
    "print(all_client_branch)\n",
    "\n",
    "# 判斷各個分支是否有更新\n",
    "if len(all_client_branch) <= 0:\n",
    "    raise ValueError('June: No clients appear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* \u001b[32mmain\u001b[m\n",
      "  \u001b[31mremotes/origin/BxipCjg_WfS0amO30vC6mQ\u001b[m\n",
      "  \u001b[31mremotes/origin/HEAD\u001b[m -> origin/main\n",
      "  \u001b[31mremotes/origin/MKkWS7qXBbnugNAEXN8PEg\u001b[m\n",
      "  \u001b[31mremotes/origin/Ntyfcj14jPRiW4iWiNa2PA\u001b[m\n",
      "  \u001b[31mremotes/origin/Rj1cKm2wIS3f3NmKrQgX1g\u001b[m\n",
      "  \u001b[31mremotes/origin/VA6GWv7MfvF1OnnLj0Ra3w\u001b[m\n",
      "  \u001b[31mremotes/origin/ZmUvKOfUgOhilDwuPALTWA\u001b[m\n",
      "  \u001b[31mremotes/origin/main\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!git branch -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_lis = [i.split('/')[-1] for i in all_client_branch]\n",
    "# for i in all_lis:\n",
    "#     if not i in [_.split('.')[0] for _ in lis]:\n",
    "#         print(i)\n",
    "#         remote_name = 'origin'\n",
    "#         branch_name = i\n",
    "#         os.popen(f'git branch -d {branch_name}')\n",
    "#         os.popen(f'git push {remote_name} --delete {branch_name}').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin/BxipCjg_WfS0amO30vC6mQ BxipCjg_WfS0amO30vC6mQ.pbz2\n",
      "\n",
      "origin/MKkWS7qXBbnugNAEXN8PEg MKkWS7qXBbnugNAEXN8PEg.pbz2\n",
      "\n",
      "origin/Ntyfcj14jPRiW4iWiNa2PA Ntyfcj14jPRiW4iWiNa2PA.pbz2\n",
      "\n",
      "origin/Rj1cKm2wIS3f3NmKrQgX1g Rj1cKm2wIS3f3NmKrQgX1g.pbz2\n",
      "\n",
      "origin/VA6GWv7MfvF1OnnLj0Ra3w VA6GWv7MfvF1OnnLj0Ra3w.pbz2\n",
      "\n",
      "origin/ZmUvKOfUgOhilDwuPALTWA ZmUvKOfUgOhilDwuPALTWA.pbz2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error: pathspec 'remotes/origin/BxipCjg_WfS0amO30vC6mQ' did not match any file(s) known to git.\n",
      "error: pathspec 'BxipCjg_WfS0amO30vC6mQ.pbz2' did not match any file(s) known to git.\n",
      "error: pathspec 'remotes/origin/MKkWS7qXBbnugNAEXN8PEg' did not match any file(s) known to git.\n",
      "error: pathspec 'MKkWS7qXBbnugNAEXN8PEg.pbz2' did not match any file(s) known to git.\n",
      "error: pathspec 'remotes/origin/Ntyfcj14jPRiW4iWiNa2PA' did not match any file(s) known to git.\n",
      "error: pathspec 'Ntyfcj14jPRiW4iWiNa2PA.pbz2' did not match any file(s) known to git.\n",
      "error: pathspec 'remotes/origin/Rj1cKm2wIS3f3NmKrQgX1g' did not match any file(s) known to git.\n",
      "error: pathspec 'Rj1cKm2wIS3f3NmKrQgX1g.pbz2' did not match any file(s) known to git.\n",
      "error: pathspec 'remotes/origin/VA6GWv7MfvF1OnnLj0Ra3w' did not match any file(s) known to git.\n",
      "error: pathspec 'VA6GWv7MfvF1OnnLj0Ra3w.pbz2' did not match any file(s) known to git.\n",
      "error: pathspec 'remotes/origin/ZmUvKOfUgOhilDwuPALTWA' did not match any file(s) known to git.\n",
      "error: pathspec 'ZmUvKOfUgOhilDwuPALTWA.pbz2' did not match any file(s) known to git.\n"
     ]
    }
   ],
   "source": [
    "run_cmd = lambda cmd_lis:[os.popen(i).read() for i in cmd_lis.split('\\n')]\n",
    "\n",
    "for i in all_client_branch:\n",
    "    origin_branch_name = i.lstrip()\n",
    "    filename = origin_branch_name.split('/')[-1]+'.pbz2'\n",
    "    \n",
    "    print(origin_branch_name, filename)\n",
    "    \n",
    "    \n",
    "    cmd_lis = '''git checkout remotes/{branch_name} {model_attri_pbz2}\n",
    "    '''.format(branch_name = origin_branch_name, model_attri_pbz2=filename)\n",
    "    result = os.popen(cmd_lis).read()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 聚合並更新global model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-18 11:18:32.782593: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-01-18 11:18:32.783440: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-01-18 11:18:32.832880: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:06:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-01-18 11:18:32.835753: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:07:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-01-18 11:18:32.838739: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties: \n",
      "pciBusID: 0000:0f:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-01-18 11:18:32.838756: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-01-18 11:18:32.841732: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2022-01-18 11:18:32.841774: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-01-18 11:18:32.843220: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-01-18 11:18:32.843500: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-01-18 11:18:32.846815: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-01-18 11:18:32.847591: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-01-18 11:18:32.847748: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-01-18 11:18:32.865063: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1, 2\n",
      "2022-01-18 11:18:32.865461: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-18 11:18:32.866018: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-01-18 11:18:33.396085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:06:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-01-18 11:18:33.398470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:07:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-01-18 11:18:33.400825: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties: \n",
      "pciBusID: 0000:0f:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-01-18 11:18:33.400862: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-01-18 11:18:33.400901: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2022-01-18 11:18:33.400920: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-01-18 11:18:33.400936: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-01-18 11:18:33.400954: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-01-18 11:18:33.400971: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-01-18 11:18:33.400988: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-01-18 11:18:33.401007: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-01-18 11:18:33.414361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1, 2\n",
      "2022-01-18 11:18:33.414395: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-01-18 11:18:34.837131: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-01-18 11:18:34.837159: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 2 \n",
      "2022-01-18 11:18:34.837165: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N Y Y \n",
      "2022-01-18 11:18:34.837169: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   Y N Y \n",
      "2022-01-18 11:18:34.837173: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 2:   Y Y N \n",
      "2022-01-18 11:18:34.848288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 174 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:06:00.0, compute capability: 6.1)\n",
      "2022-01-18 11:18:34.854494: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10037 MB memory) -> physical GPU (device: 1, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:07:00.0, compute capability: 6.1)\n",
      "2022-01-18 11:18:34.859369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 10037 MB memory) -> physical GPU (device: 2, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:0f:00.0, compute capability: 6.1)\n",
      "2022-01-18 11:18:34.868243: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 174.38M (182845440 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n"
     ]
    }
   ],
   "source": [
    "model_attri = decompress_cpickle('./global_model.pbz2')\n",
    "global_model = tf.keras.models.model_from_json(model_attri['json'])\n",
    "\n",
    "lis = [i for i in os.listdir() if i.__contains__('pbz2')]\n",
    "lis.remove('global_model.pbz2')\n",
    "print(lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0,)\n"
     ]
    }
   ],
   "source": [
    "lis = [i for i in os.listdir() if i.__contains__('pbz2')]\n",
    "lis.remove('global_model.pbz2')\n",
    "\n",
    "weights = []\n",
    "for i in lis:\n",
    "    model_attri = decompress_cpickle(i)\n",
    "    weights.append(model_attri['weights'])\n",
    "print(np.shape(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no new client to aggregate\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You called `set_weights(weights)` on layer \"model\" with a weight list of length 0, but the layer was expecting 10 weights. Provided weights: []...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1494/2617411142.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mnew_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mglobal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mset_weights\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m   1855\u001b[0m           \u001b[0;34m'with a weight list of length %s, but the layer was '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1856\u001b[0m           \u001b[0;34m'expecting %s weights. Provided weights: %s...'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1857\u001b[0;31m           (self.name, len(weights), expected_num_weights, str(weights)[:50]))\n\u001b[0m\u001b[1;32m   1858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1859\u001b[0m     \u001b[0mweight_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You called `set_weights(weights)` on layer \"model\" with a weight list of length 0, but the layer was expecting 10 weights. Provided weights: []..."
     ]
    }
   ],
   "source": [
    "new_weights = list()\n",
    "if len(weights) == 0:\n",
    "    print('no new client to aggregate')\n",
    "    pass\n",
    "elif len(weights) == 1:\n",
    "    print('only single participant')\n",
    "    new_weights = weights[0]\n",
    "else:\n",
    "    for i in zip(*weights):\n",
    "        new_weights.append(tf.reduce_sum(i, axis=0))\n",
    "        \n",
    "global_model.set_weights(new_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_attri = {'weights':global_model.get_weights(), 'json':global_model.to_json()}\n",
    "\n",
    "compressed_cpickle('./global_model', model_attri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "run_cmd = lambda cmd_lis:[os.popen(i).read() for i in cmd_lis.split('\\n')]\n",
    "\n",
    "cmd_lis = '''mv ./global_model.pbz2 ../\n",
    "rm *.pbz2\n",
    "mv ../global_model.pbz2 ./\n",
    "git add .\n",
    "git commit -m'global model complete aggregate and update to Gmodel'\n",
    "git push https://{account}@{gitURL}\n",
    "'''.format(account=account, gitURL=gitURL.split('//')[-1])\n",
    "\n",
    "\n",
    "run_cmd(cmd_lis)\n",
    "branch = os.popen('git branch -a').read()\n",
    "print(branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
