{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Dropout, LSTM, SimpleRNN, GRU\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from client_setup import client_k\n",
    "from utils import compressed_cpickle, decompress_cpickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning.cfg already existed\n"
     ]
    }
   ],
   "source": [
    "class client_env_setup():\n",
    "    def __init__(self):\n",
    "        self.key = self.generate_key()\n",
    "        self.save_cfg()\n",
    "    def generate_key(self):\n",
    "        import secrets\n",
    "        key = secrets.token_urlsafe(16)\n",
    "        return key\n",
    "    \n",
    "    def save_cfg(self):\n",
    "        print('Create learning.cfg')\n",
    "        with open('./learning.cfg', mode='w+', encoding='UTF-8') as f:\n",
    "            r = f.readline()\n",
    "            print(r)\n",
    "            f.writelines('key='+self.key)\n",
    "# generate_key()\n",
    "if 'learning.cfg' in os.listdir():\n",
    "    print('learning.cfg already existed')\n",
    "    pass\n",
    "else:\n",
    "    a = client_env_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 標準化數據\n",
    "X_train = X_train/255.0\n",
    "X_test = X_test/255.0\n",
    "print(X_train.shape)\n",
    "print(X_train[0].shape)\n",
    "\n",
    "idx = np.argsort(y_train)\n",
    "x_train_sorted = X_train[idx]\n",
    "y_train_sorted = y_train[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "width = 1000\n",
    "index = np.random.choice(len(x_train_sorted)-width, 1)[0]\n",
    "index = range(index, index+width) \n",
    "x = x_train_sorted[index]\n",
    "y = y_train_sorted[index]\n",
    "\n",
    "print(np.unique(y_train))\n",
    "print(len(x))\n",
    "print(len(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_attri = decompress_cpickle('../global_model.pbz2')\n",
    "\n",
    "model = tf.keras.models.model_from_json(model_attri['json'])\n",
    "model.set_weights(model_attri['weights'])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    "\n",
    "model.compile(optimizer, loss_fn,\n",
    "                          metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = 'model-logs'\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "logfiles = model_dir + '/{}-{}'.format('basic_model', model.__class__.__name__)\n",
    "model_cbk = tf.keras.callbacks.TensorBoard(log_dir=logfiles,\n",
    "                                        histogram_freq=1)\n",
    "\n",
    "modelfiles = model_dir + '/{}-best-model.h5'.format('basic_model')\n",
    "model_mckp = tf.keras.callbacks.ModelCheckpoint(modelfiles,\n",
    "                                             monitor='val_accuracy',\n",
    "                                             save_best_only=True)\n",
    "\n",
    "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                          patience=5,\n",
    "                                          verbose=1)\n",
    "\n",
    "\n",
    "# callbacks_list = [model_cbk, model_mckp, earlystop]\n",
    "callbacks_list = [earlystop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "25/25 - 0s - loss: 2.3006 - sparse_categorical_accuracy: 0.0137 - val_loss: 2.2998 - val_sparse_categorical_accuracy: 0.0200\n",
      "Epoch 2/30\n",
      "25/25 - 0s - loss: 2.2990 - sparse_categorical_accuracy: 0.0525 - val_loss: 2.2982 - val_sparse_categorical_accuracy: 0.0900\n",
      "Epoch 3/30\n",
      "25/25 - 0s - loss: 2.2974 - sparse_categorical_accuracy: 0.1912 - val_loss: 2.2965 - val_sparse_categorical_accuracy: 0.3150\n",
      "Epoch 4/30\n",
      "25/25 - 0s - loss: 2.2956 - sparse_categorical_accuracy: 0.4812 - val_loss: 2.2948 - val_sparse_categorical_accuracy: 0.6650\n",
      "Epoch 5/30\n",
      "25/25 - 0s - loss: 2.2939 - sparse_categorical_accuracy: 0.7925 - val_loss: 2.2930 - val_sparse_categorical_accuracy: 0.9000\n",
      "Epoch 6/30\n",
      "25/25 - 0s - loss: 2.2920 - sparse_categorical_accuracy: 0.9450 - val_loss: 2.2911 - val_sparse_categorical_accuracy: 0.9850\n",
      "Epoch 7/30\n",
      "25/25 - 0s - loss: 2.2901 - sparse_categorical_accuracy: 0.9962 - val_loss: 2.2892 - val_sparse_categorical_accuracy: 0.9950\n",
      "Epoch 8/30\n",
      "25/25 - 0s - loss: 2.2881 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.2871 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "25/25 - 0s - loss: 2.2859 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.2850 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "25/25 - 0s - loss: 2.2837 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.2827 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "25/25 - 0s - loss: 2.2813 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.2802 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "25/25 - 0s - loss: 2.2787 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.2775 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "25/25 - 0s - loss: 2.2759 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.2746 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "25/25 - 0s - loss: 2.2728 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.2715 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "25/25 - 0s - loss: 2.2694 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.2680 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "25/25 - 0s - loss: 2.2657 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.2640 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "25/25 - 0s - loss: 2.2615 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.2596 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "25/25 - 0s - loss: 2.2567 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.2546 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "25/25 - 0s - loss: 2.2512 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.2487 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "25/25 - 0s - loss: 2.2447 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.2417 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "25/25 - 0s - loss: 2.2370 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.2333 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "25/25 - 0s - loss: 2.2275 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.2229 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "25/25 - 0s - loss: 2.2156 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.2095 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "25/25 - 0s - loss: 2.1999 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.1916 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "25/25 - 0s - loss: 2.1784 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.1663 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "25/25 - 0s - loss: 2.1468 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.1278 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "25/25 - 0s - loss: 2.0963 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.0633 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "25/25 - 0s - loss: 2.0077 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.9467 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "25/25 - 0s - loss: 1.8547 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.7646 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "25/25 - 0s - loss: 1.6748 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.6114 - val_sparse_categorical_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 30\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=callbacks_list,\n",
    "                    verbose = 2\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 1ms/step - loss: 1.6114 - sparse_categorical_accuracy: 1.0000\n",
      "test loss, test acc: [1.611357569694519, 1.0]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['key=0w2jsKym8GjaDhipfpFCVg']\n"
     ]
    }
   ],
   "source": [
    "# weight、架構 (json) to pickle\n",
    "\n",
    "model_attri = {'weights':model.get_weights(), 'json':model.to_json()}\n",
    "\n",
    "\n",
    "with open('./learning.cfg', mode='r', encoding='UTF-8') as f:\n",
    "    r = f.readlines()\n",
    "    item_dict = {}\n",
    "    for item in r:\n",
    "        key, value = item.split('=')\n",
    "        item_dict[key] = value\n",
    "    print(r)\n",
    "\n",
    "compressed_cpickle(item_dict['key'], model_attri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '', '', '', '']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "run_cmd = lambda cmd_lis:[os.popen(i).read() for i in cmd_lis.split('\\n')]\n",
    "\n",
    "cmd_lis = '''git clone https://at102091:12345678@gitlab.aiacademy.tw/junew/federated_aia_test.git\n",
    "git branch {key}\n",
    "git fetch\n",
    "git checkout {new_branch}\n",
    "'''.format(key=item_dict['key'], new_branch=key)\n",
    "\n",
    "run_cmd(cmd_lis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0w2jsKym8GjaDhipfpFCVg\u001b[m\n",
      "* \u001b[32mmain\u001b[m\n",
      "  \u001b[31mremotes/origin/HEAD\u001b[m -> origin/main\n",
      "  \u001b[31mremotes/origin/main\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!git branch -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def push_aiamenber_csv():\n",
    "\n",
    "    run_cmd = lambda cmd_lis:[os.popen(i).read() for i in cmd_lis.split('\\n')]\n",
    "\n",
    "    cmd_lis = '''ls\n",
    "    cp ../aiaMenber.csv .\n",
    "    git config --global user.email \"at102091@aiacademy.tw\"\n",
    "    git config --global user.name \"at102091\"\n",
    "    git add .\n",
    "    git commit -m'update aia menber csv'\n",
    "    git push https://at102091:at102091@gitlab.aiacademy.tw/junew/AIA_chatbot.git\n",
    "    '''\n",
    "    os.chdir('AIA_chatbot')\n",
    "    run_cmd(cmd_lis)\n",
    "    os.chdir('..')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
