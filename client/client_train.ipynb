{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Dropout, LSTM, SimpleRNN, GRU\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from client_setup import client_k\n",
    "from utils import compressed_cpickle, decompress_cpickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning.cfg already existed\n"
     ]
    }
   ],
   "source": [
    "class client_env_setup():\n",
    "    def __init__(self):\n",
    "        self.key = self.generate_key()\n",
    "        self.save_cfg()\n",
    "    def generate_key(self):\n",
    "        import secrets\n",
    "        key = secrets.token_urlsafe(16)\n",
    "        return key\n",
    "    \n",
    "    def save_cfg(self):\n",
    "        print('Create learning.cfg')\n",
    "        with open('./learning.cfg', mode='w+', encoding='UTF-8') as f:\n",
    "            r = f.readline()\n",
    "            print(r)\n",
    "            f.writelines('key='+self.key)\n",
    "# generate_key()\n",
    "if 'learning.cfg' in os.listdir():\n",
    "    print('learning.cfg already existed')\n",
    "    pass\n",
    "else:\n",
    "    a = client_env_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 標準化數據\n",
    "X_train = X_train/255.0\n",
    "X_test = X_test/255.0\n",
    "print(X_train.shape)\n",
    "print(X_train[0].shape)\n",
    "\n",
    "idx = np.argsort(y_train)\n",
    "x_train_sorted = X_train[idx]\n",
    "y_train_sorted = y_train[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "width = 1000\n",
    "index = np.random.choice(len(x_train_sorted)-width, 1)[0]\n",
    "index = range(index, index+width) \n",
    "x = x_train_sorted[index]\n",
    "y = y_train_sorted[index]\n",
    "\n",
    "print(np.unique(y_train))\n",
    "print(len(x))\n",
    "print(len(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_attri = decompress_cpickle('../global_model.pbz2')\n",
    "\n",
    "model = tf.keras.models.model_from_json(model_attri['json'])\n",
    "model.set_weights(model_attri['weights'])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    "\n",
    "model.compile(optimizer, loss_fn,\n",
    "                          metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = 'model-logs'\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "logfiles = model_dir + '/{}-{}'.format('basic_model', model.__class__.__name__)\n",
    "model_cbk = tf.keras.callbacks.TensorBoard(log_dir=logfiles,\n",
    "                                        histogram_freq=1)\n",
    "\n",
    "modelfiles = model_dir + '/{}-best-model.h5'.format('basic_model')\n",
    "model_mckp = tf.keras.callbacks.ModelCheckpoint(modelfiles,\n",
    "                                             monitor='val_accuracy',\n",
    "                                             save_best_only=True)\n",
    "\n",
    "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                          patience=5,\n",
    "                                          verbose=1)\n",
    "\n",
    "\n",
    "# callbacks_list = [model_cbk, model_mckp, earlystop]\n",
    "callbacks_list = [earlystop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "25/25 - 0s - loss: 2.3030 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 2.3021 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "25/25 - 0s - loss: 2.3013 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 2.3005 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "25/25 - 0s - loss: 2.2997 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 2.2988 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "25/25 - 0s - loss: 2.2979 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 2.2970 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "25/25 - 0s - loss: 2.2961 - sparse_categorical_accuracy: 0.0025 - val_loss: 2.2951 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "25/25 - 0s - loss: 2.2941 - sparse_categorical_accuracy: 0.0262 - val_loss: 2.2931 - val_sparse_categorical_accuracy: 0.0250\n",
      "Epoch 7/30\n",
      "25/25 - 0s - loss: 2.2921 - sparse_categorical_accuracy: 0.1562 - val_loss: 2.2910 - val_sparse_categorical_accuracy: 0.2150\n",
      "Epoch 8/30\n",
      "25/25 - 0s - loss: 2.2900 - sparse_categorical_accuracy: 0.4437 - val_loss: 2.2888 - val_sparse_categorical_accuracy: 0.5650\n",
      "Epoch 9/30\n",
      "25/25 - 0s - loss: 2.2877 - sparse_categorical_accuracy: 0.7738 - val_loss: 2.2864 - val_sparse_categorical_accuracy: 0.8700\n",
      "Epoch 10/30\n",
      "25/25 - 0s - loss: 2.2853 - sparse_categorical_accuracy: 0.9563 - val_loss: 2.2839 - val_sparse_categorical_accuracy: 0.9850\n",
      "Epoch 11/30\n",
      "25/25 - 0s - loss: 2.2827 - sparse_categorical_accuracy: 0.9937 - val_loss: 2.2812 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "25/25 - 0s - loss: 2.2799 - sparse_categorical_accuracy: 0.9987 - val_loss: 2.2783 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "25/25 - 0s - loss: 2.2770 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.2752 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "25/25 - 0s - loss: 2.2737 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.2718 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "25/25 - 0s - loss: 2.2702 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.2681 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "25/25 - 0s - loss: 2.2663 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.2639 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "25/25 - 0s - loss: 2.2620 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.2593 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "25/25 - 0s - loss: 2.2571 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.2540 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "25/25 - 0s - loss: 2.2515 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.2478 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "25/25 - 0s - loss: 2.2450 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.2406 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "25/25 - 0s - loss: 2.2372 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.2320 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "25/25 - 0s - loss: 2.2277 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.2213 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "25/25 - 0s - loss: 2.2159 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.2076 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "25/25 - 0s - loss: 2.2004 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.1894 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "25/25 - 0s - loss: 2.1793 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.1638 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "25/25 - 0s - loss: 2.1488 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.1254 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "25/25 - 0s - loss: 2.1008 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.0622 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "25/25 - 0s - loss: 2.0182 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.9499 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "25/25 - 0s - loss: 1.8747 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.7712 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "25/25 - 0s - loss: 1.6944 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.6114 - val_sparse_categorical_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 30\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=callbacks_list,\n",
    "                    verbose = 2\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 1ms/step - loss: 1.6114 - sparse_categorical_accuracy: 1.0000\n",
      "test loss, test acc: [1.6113744974136353, 1.0]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['key=0w2jsKym8GjaDhipfpFCVg']\n"
     ]
    }
   ],
   "source": [
    "# weight、架構 (json) to pickle\n",
    "\n",
    "model_attri = {'weights':model.get_weights(), 'json':model.to_json()}\n",
    "\n",
    "\n",
    "with open('./learning.cfg', mode='r', encoding='UTF-8') as f:\n",
    "    r = f.readlines()\n",
    "    item_dict = {}\n",
    "    for item in r:\n",
    "        key, value = item.split('=')\n",
    "        item_dict[key] = value\n",
    "    print(r)\n",
    "\n",
    "compressed_cpickle(item_dict['key'], model_attri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32768"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "result = os.system('git clone https://gitlab.aiacademy.tw/junew/federated_aia_test.git')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def push_aiamenber_csv():\n",
    "\n",
    "    run_cmd = lambda cmd_lis:[os.popen(i).read() for i in cmd_lis.split('\\n')]\n",
    "\n",
    "    cmd_lis = '''ls\n",
    "    cp ../aiaMenber.csv .\n",
    "    git config --global user.email \"at102091@aiacademy.tw\"\n",
    "    git config --global user.name \"at102091\"\n",
    "    git add .\n",
    "    git commit -m'update aia menber csv'\n",
    "    git push https://at102091:at102091@gitlab.aiacademy.tw/junew/AIA_chatbot.git\n",
    "    '''\n",
    "    os.chdir('AIA_chatbot')\n",
    "    run_cmd(cmd_lis)\n",
    "    os.chdir('..')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
