{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FedAVG\n",
    "- dataset: \n",
    "    - MNIST/ CIFAR10\n",
    "    - stock?\n",
    "    \n",
    "<!-- <img src=\"slide_image/FedAvg_MNIST.png\" width=640  /> -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile test.py \n",
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--rounds\", help=\"aggregation rounds\",\n",
    "                    type=int)\n",
    "args = parser.parse_args()\n",
    "\n",
    "rounds_ = args.rounds\n",
    "if not rounds_:\n",
    "    raise ValueError('***Plz type in aggregation rounds***')\n",
    "# print(rounds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices(device_type='GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(device=gpu, enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (Input, Dense, Dropout, Activation,\n",
    "                                     BatchNormalization, Flatten,\n",
    "                                     Conv2D, MaxPooling2D)\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom func."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplecnn(name):\n",
    "    # 選擇 Keras 的 API 寫法\n",
    "    inputs = Input(shape=(28,28,1))\n",
    "\n",
    "    # 第一層\n",
    "    # 建立卷積層，設定32個3*3的filters\n",
    "    # 設定ReLU為激活函數。\n",
    "    x = Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "\n",
    "    # 第二層 - 卷積層 + 池化層\n",
    "    x = Conv2D(32, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # 第三層 - 卷積層\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "\n",
    "    # 第四層 - 卷積層 + 池化層\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # 建立分類模型 (MLP) : 平坦層 + 輸出層 (10)\n",
    "    x = Flatten()(x)\n",
    "    outputs = Dense(10, activation='softmax')(x)\n",
    "\n",
    "    cnn_model = Model(inputs=inputs, outputs=outputs)\n",
    "    return cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_trainable(model, under):\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[under:]:\n",
    "        layer.trainable = True\n",
    "        \n",
    "    for i in model.layers:\n",
    "        print(i.trainable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(X_train, y_train), (X_test_origin, y_test_origin) = mnist.load_data()\n",
    "\n",
    "# 標準化數據\n",
    "X_train = X_train/255.0\n",
    "X_test_origin = X_test_origin/255.0\n",
    "print(X_train.shape)\n",
    "print(X_train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.argsort(y_train)\n",
    "x_train_sorted = X_train[idx]\n",
    "y_train_sorted = y_train[idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = simplecnn('server_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### aggregation func."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import clone_model\n",
    "\n",
    "def avg_weight(choice, Gmodel, client_list):\n",
    "    tmp_model = clone_model(Gmodel) # Gmdoel  \n",
    "    tmp_model.set_weights(Gmodel.get_weights()) # Gmdoel servermodel\n",
    "    models = []\n",
    "    weighting = []\n",
    "    for _ in choice: # idx of selected client\n",
    "        models.append(client_list['client'+str(_)].model)\n",
    "        weighting.append(len(client_list['client'+str(_)].data))\n",
    "        \n",
    "    weights = [model.get_weights() for model in models]\n",
    "    new_weights = list()\n",
    "    \n",
    "    weighting = np.array(weighting)/np.sum(weighting)\n",
    "\n",
    "    weights = [i for i in weights]\n",
    "    \n",
    "    for i in zip(*weights):\n",
    "        a = np.average(i, weights=weighting, axis=0)\n",
    "        new_weights.append(a)\n",
    "    \n",
    "    pt = 0\n",
    "    for i in range(len(tmp_model.layers)):\n",
    "        a = tmp_model.layers[i]\n",
    "\n",
    "        if len(a.get_weights()) != 0:\n",
    "            a.set_weights(new_weights[pt:len(a.get_weights())+pt])\n",
    "            pt+=len(a.get_weights())\n",
    "    del models, weighting, new_weights\n",
    "    return tmp_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_check(model_1, model_2):\n",
    "    a = model_1.get_weights()\n",
    "    for i in range(len(a)):\n",
    "#         print(i)\n",
    "        if np.array_equal(model_1.get_weights()[i], model_2.get_weights()[i]):\n",
    "            print('layer %d is equal'%i)\n",
    "            pass\n",
    "        else:\n",
    "#             print('Model not equal')\n",
    "            print('layer %d is not equal'%i)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Client "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define clinet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class clint_k():\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        \n",
    "        self.attri = {'name':self.name}\n",
    "    def set_content(self, data, label, model):\n",
    "        content = {'name': self.name, 'data':data, 'label':label, 'model':model}\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.model = model\n",
    "        values_list = [self.name, self.data, self.label, self.model]\n",
    "        keys_list = ['name','data', 'label', 'model']\n",
    "        self.attri = dict(zip(keys_list, values_list))\n",
    "        return content\n",
    "    def show_content(self):\n",
    "\n",
    "        return self.attri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stuff data, model into client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "def split_client(x, y, method = bySample_bal_split, K = 6):\n",
    "    \n",
    "#     hyper_para['K'] \n",
    "    K = K\n",
    "\n",
    "    split_method = {}\n",
    "    # split_method['method'] = lambda x,y,k : byClasses_inbal_split(x,y,k)\n",
    "    split_method['method'] = bySample_bal_split\n",
    "\n",
    "\n",
    "    subset= split_method['method'](x_train_sorted, y_train_sorted, K)\n",
    "    view_clientDict(subset)\n",
    "    return subset\n",
    "    \n",
    "# _ = split_client(x_train_sorted, y_train_sorted, bySample_bal_split, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train_, y_train_))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).prefetch(batch_size).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> 分割給 4 個client\n",
      ">>> subset client0 資料維度\n",
      "-- data shape (15000, 28, 28) --label shape (15000,)\n",
      ">>> subset client3 資料維度\n",
      "-- data shape (15000, 28, 28) --label shape (15000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['client0', 'client1', 'client2', 'client3'])\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import clone_model\n",
    "\n",
    "\n",
    "Gmodel = simplecnn('server_model')\n",
    "\n",
    "hyper_para = dict()\n",
    "hyper_para['K'] = 4\n",
    "subset = split_client(x_train_sorted, y_train_sorted, bySample_bal_split, hyper_para['K'])\n",
    "\n",
    "client_list = dict() \n",
    "\n",
    "for _ in list(subset.keys()):\n",
    "\n",
    "    client_list[_] = clint_k(_)\n",
    "    client_list[_].set_content(data = subset[_][0], # setting data and weight\n",
    "                               label = subset[_][1], model = clone_model(Gmodel))\n",
    "    client_list[_].model.set_weights(Gmodel.get_weights())\n",
    "print(client_list.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'K': 4, 'B': 1024, 'C': 0.5, 'E': 3, 'mu': 0}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# batchsize\n",
    "hyper_para['B'] = 1024\n",
    "\n",
    "# choice\n",
    "# C = 1\n",
    "hyper_para['C'] = 0.5\n",
    "\n",
    "# Epochs\n",
    "hyper_para['E'] = 3\n",
    "\n",
    "hyper_para['mu'] = 0\n",
    "\n",
    "\n",
    "print(hyper_para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score\n",
    "# import numpy as np\n",
    "    \n",
    "# def acc_model(X_test, y_test, model, num):\n",
    "\n",
    "    \n",
    "#     a = np.random.choice(len(X_test), num)\n",
    "# #     print(a)\n",
    "#     y_pred = model.predict(X_test[a])\n",
    "#     y_pred = np.argmax(y_pred,axis=1)\n",
    "#     print(y_pred[0:10])\n",
    "#     y_true = y_test[a]\n",
    "#     print(y_true[0:10])\n",
    "# #     print(accuracy_score(y_true, y_pred))\n",
    "#     return accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = Gmodel.weights[0]\n",
    "# tf.norm(a)\n",
    "# tf.norm([tf.norm(a) for a in Gmodel.weights])\n",
    "# # tf.norm(b, axis=[-2,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "*************************************\n",
      "Training on client3\n",
      "Training acc over epoch: 0.4310\n",
      "Training acc over epoch: 0.7375\n",
      "Training acc over epoch: 0.7641\n",
      "Time taken: 4.07s\n",
      "*************************************\n",
      "Training on client1\n",
      "Training acc over epoch: 0.6236\n",
      "Training acc over epoch: 0.7453\n",
      "Training acc over epoch: 0.7518\n",
      "Time taken: 2.51s\n",
      "Global model Validation acc on global valdation set: 0.2112\n",
      "1\n",
      "*************************************\n",
      "Training on client2\n",
      "Training acc over epoch: 0.0697\n",
      "Training acc over epoch: 0.2376\n",
      "Training acc over epoch: 0.2429\n",
      "Time taken: 2.51s\n",
      "*************************************\n",
      "Training on client1\n",
      "Training acc over epoch: 0.7217\n",
      "Training acc over epoch: 0.7501\n",
      "Training acc over epoch: 0.7533\n",
      "Time taken: 2.51s\n",
      "Global model Validation acc on global valdation set: 0.1542\n",
      "2\n",
      "*************************************\n",
      "Training on client0\n",
      "Training acc over epoch: 0.0081\n",
      "Training acc over epoch: 0.1561\n",
      "Training acc over epoch: 0.8218\n",
      "Time taken: 2.51s\n",
      "*************************************\n",
      "Training on client3\n",
      "Training acc over epoch: 0.4709\n",
      "Training acc over epoch: 0.5924\n",
      "Training acc over epoch: 0.8812\n",
      "Time taken: 2.50s\n",
      "Global model Validation acc on global valdation set: 0.3544\n",
      "3\n",
      "*************************************\n",
      "Training on client1\n",
      "Training acc over epoch: 0.6504\n",
      "Training acc over epoch: 0.9402\n",
      "Training acc over epoch: 0.9651\n",
      "Time taken: 2.50s\n",
      "*************************************\n",
      "Training on client0\n",
      "Training acc over epoch: 0.9813\n",
      "Training acc over epoch: 0.9879\n",
      "Training acc over epoch: 0.9902\n",
      "Time taken: 2.50s\n",
      "Global model Validation acc on global valdation set: 0.2701\n",
      "4\n",
      "*************************************\n",
      "Training on client3\n",
      "Training acc over epoch: 0.3407\n",
      "Training acc over epoch: 0.7239\n",
      "Training acc over epoch: 0.9419\n",
      "Time taken: 2.53s\n",
      "*************************************\n",
      "Training on client0\n",
      "Training acc over epoch: 0.9296\n",
      "Training acc over epoch: 0.9856\n",
      "Training acc over epoch: 0.9880\n",
      "Time taken: 2.50s\n",
      "Global model Validation acc on global valdation set: 0.5538\n",
      "5\n",
      "*************************************\n",
      "Training on client3\n",
      "Training acc over epoch: 0.9463\n",
      "Training acc over epoch: 0.9679\n",
      "Training acc over epoch: 0.9781\n",
      "Time taken: 2.50s\n",
      "*************************************\n",
      "Training on client0\n",
      "Training acc over epoch: 0.9844\n",
      "Training acc over epoch: 0.9919\n",
      "Training acc over epoch: 0.9938\n",
      "Time taken: 2.50s\n",
      "Global model Validation acc on global valdation set: 0.5438\n",
      "6\n",
      "*************************************\n",
      "Training on client0\n",
      "Training acc over epoch: 0.9924\n",
      "Training acc over epoch: 0.9947\n",
      "Training acc over epoch: 0.9961\n",
      "Time taken: 2.50s\n",
      "*************************************\n",
      "Training on client3\n",
      "Training acc over epoch: 0.9529\n",
      "Training acc over epoch: 0.9787\n",
      "Training acc over epoch: 0.9830\n",
      "Time taken: 2.52s\n",
      "Global model Validation acc on global valdation set: 0.5681\n",
      "7\n",
      "*************************************\n",
      "Training on client0\n",
      "Training acc over epoch: 0.9873\n",
      "Training acc over epoch: 0.9962\n",
      "Training acc over epoch: 0.9967\n",
      "Time taken: 2.50s\n",
      "*************************************\n",
      "Training on client2\n",
      "Training acc over epoch: 0.2030\n",
      "Training acc over epoch: 0.6172\n",
      "Training acc over epoch: 0.9687\n",
      "Time taken: 2.51s\n",
      "Global model Validation acc on global valdation set: 0.6256\n",
      "8\n",
      "*************************************\n",
      "Training on client1\n",
      "Training acc over epoch: 0.5819\n",
      "Training acc over epoch: 0.7705\n",
      "Training acc over epoch: 0.9707\n",
      "Time taken: 2.50s\n",
      "*************************************\n",
      "Training on client0\n",
      "Training acc over epoch: 0.9930\n",
      "Training acc over epoch: 0.9960\n",
      "Training acc over epoch: 0.9970\n",
      "Time taken: 2.51s\n",
      "Global model Validation acc on global valdation set: 0.4289\n",
      "9\n",
      "*************************************\n",
      "Training on client2\n",
      "Training acc over epoch: 0.5518\n",
      "Training acc over epoch: 0.9456\n",
      "Training acc over epoch: 0.9508\n",
      "Time taken: 2.52s\n",
      "*************************************\n",
      "Training on client0\n",
      "Training acc over epoch: 0.9796\n",
      "Training acc over epoch: 0.9953\n",
      "Training acc over epoch: 0.9959\n",
      "Time taken: 2.50s\n",
      "Global model Validation acc on global valdation set: 0.4824\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "acc_test = []\n",
    "\n",
    "if not 'rounds_' in list(locals().keys()):\n",
    "    rounds_ = 10\n",
    "for rounds in range(rounds_):\n",
    "    print(rounds)\n",
    "    clients = range(hyper_para['K'])\n",
    "    \n",
    "    size = int(np.ceil(hyper_para['C']*hyper_para['K']))\n",
    "    choice = np.random.choice(clients, size = size, replace=False)\n",
    "\n",
    "\n",
    "    #--------------------\n",
    "    batch_size = hyper_para['B']\n",
    "    epochs = hyper_para['E']\n",
    "    u = hyper_para['mu']\n",
    "\n",
    "\n",
    "    for _ in choice:\n",
    "        print('*************************************')\n",
    "        print('Training on client'+str(_))\n",
    "        client = client_list['client'+str(_)]\n",
    "\n",
    "        \n",
    "        model = client.model\n",
    "        \n",
    "        # Instantiate an optimizer to train the model.\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "        # Instantiate a loss function.\n",
    "        loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "        \n",
    "        # Prepare the metrics.\n",
    "        train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "#         val_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "        \n",
    "\n",
    "        X_train_, X_test_, y_train_, y_test_ = train_test_split(\n",
    "                client.data, client.label, test_size=0.1)\n",
    "\n",
    "\n",
    "        # Prepare the training dataset.\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((X_train_, y_train_))\n",
    "#         train_dataset = train_dataset.shuffle(buffer_size=1024).prefetch(batch_size).batch(batch_size)\n",
    "        train_dataset = train_dataset.shuffle(buffer_size=1024).prefetch(batch_size).batch(batch_size)\n",
    "        \n",
    "#         train_acc = []\n",
    "        \n",
    "        #------------------------------------------\n",
    "        start_time = time.time()\n",
    "        for epoch in range(epochs):\n",
    "#             print('epoch = ',epoch)\n",
    "            # Iterate over the batches of the dataset.\n",
    "            for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "\n",
    "                # Open a GradientTape to record the operations run\n",
    "                # during the forward pass, which enables auto-differentiation.\n",
    "                with tf.GradientTape(persistent=True) as tape:\n",
    "\n",
    "                    # Run the forward pass of the layer.\n",
    "                    # The operations that the layer applies\n",
    "                    # to its inputs are going to be recorded\n",
    "                    # on the GradientTape.\n",
    "                    logits = model(x_batch_train, training=True)  # Logits for this minibatch\n",
    "\n",
    "                    # Compute the loss value for this minibatch.\n",
    "                    loss_value = loss_fn(y_batch_train, logits)\n",
    "#                     print(loss_value)\n",
    "\n",
    "\n",
    "                    ## proximal term ========================================================\n",
    "                    weights = [model.get_weights() for model in [model, Gmodel]]\n",
    "                    new_weights = list()\n",
    "\n",
    "                    for weights_list_tuple in zip(*weights):\n",
    "                        new_weights.append(\n",
    "                            [np.subtract(weights_[0], weights_[1])\\\n",
    "                                for weights_ in zip(*weights_list_tuple)])\n",
    "                    weight_diff = new_weights\n",
    "                    diff_2norm =  tf.norm([tf.norm(a) for a in weight_diff])\n",
    "\n",
    "                    \n",
    "                    proximal_term = 0.5*u*diff_2norm\n",
    "                    loss_value+=proximal_term\n",
    "                ## proximal term End ========================================================\n",
    "    \n",
    "                # Use the gradient tape to automatically retrieve\n",
    "                # the gradients of the trainable variables with respect to the loss.\n",
    "                grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "                \n",
    "                # Run one step of gradient descent by updating\n",
    "                # the value of the variables to minimize the loss.\n",
    "                optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "                \n",
    "            \n",
    "                # Update training metric.\n",
    "                train_acc_metric.update_state(y_batch_train, logits)\n",
    "                \n",
    "                \n",
    "            # Display metrics at the end of each epoch.\n",
    "            train_acc = train_acc_metric.result()\n",
    "            print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
    "#             train_acc.append(float(train_acc)) # 取得 acc\n",
    "            \n",
    "            # Reset training metrics at the end of each epoch\n",
    "            train_acc_metric.reset_states()\n",
    "        \n",
    "            \n",
    "        \n",
    "        print(\"Time taken: %.2fs\" % (time.time() - start_time))\n",
    "        #----------------------------------\n",
    "        \n",
    "    \n",
    "    Gmodel = avg_weight(choice, Gmodel, client_list)\n",
    "    for i in client_list:\n",
    "        client_list[i].model.set_weights(Gmodel.get_weights()) \n",
    "\n",
    "        \n",
    "        \n",
    "    # Prepare the global validation dataset. \n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((X_test_origin, y_test_origin))\n",
    "    val_dataset = val_dataset.batch(batch_size//10)\n",
    "    \n",
    "    val_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "#     if rounds % 5 == 0:\n",
    "        \n",
    "    for x_batch_val, y_batch_val in val_dataset:\n",
    "            val_logits = Gmodel(x_batch_val, training=False)\n",
    "            # Update val metrics\n",
    "            val_acc_metric.update_state(y_batch_val, val_logits)\n",
    "    val_acc = val_acc_metric.result()\n",
    "    val_acc_metric.reset_states()\n",
    "    print(\"Global model Validation acc on global valdation set: %.4f\" % (float(val_acc),))\n",
    "\n",
    "    acc_test.append(float(val_acc))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "df = pd.DataFrame(acc_test, columns=['Gmodel acc'])\n",
    "\n",
    "df['hyper_keys'] = pd.DataFrame(hyper_para.keys())\n",
    "df['hyper_item'] = pd.DataFrame(hyper_para.values())\n",
    "\n",
    "\n",
    "df.to_csv('./data/acc_test_'+timestr+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
